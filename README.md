# Berkeley
Garbage collector

test.exe представляет из себя скомпанованный exe-файл из Py-скрипта, интерпретатора языка Python и необходимых модулей (requests, BeautifulSoup).

Для успешного выполнения программы необходимо:
  1. Наличие подключения к сети Интернет;
  2. Существования директории (папки) pdf (!!!) рядом с исполняемым exe-файлом.
  
Результатом работы программы станет наличие 20 pdf-файлов в директории /pdf. Источником скаченных файлов является фильтрованный по IT- и инженерно-прикладным тематикам архив научных статей Калифорнийского университета в Беркли (https://escholarship.org/search?campuses=ucb&departments=iber_resin&departments=citris&departments=crest&departments=cedr&disciplines=Engineering&disciplines=Physical+Sciences+and+Mathematics&type_of_work=article).

Примечание:
  1. Результатом работы фильтра архива стало 406 статей, но на выходе программы только 20 статей (pdf-файлов) в силу выполнения задачи демонстрации работы алгоритма, а не выкачивания всех статей (хотя в исходном коде программы, закомментированно значение переменной цикла для "боевого" применения программы).
  2. Общее время выполнения программы получается из следующих этапов:
        2.1 "установка" интерпретатора языка Python на host-машину;
        2.2 процедурное выполнение исходного кода;
        2.3 "холостые" многоповторные http-запросы.
  3. Пути уменьшения общего времени выполнения программы:
        a. использование мультипроцессорности (за счет мощностей host-машины);
        b. увеличение пропускной способности интернет-соединения;
        c. проработка алгоритма, с целью уменьшения занимаемого стека-памяти RAM (в т.ч. уменьшение количества "холостых" http-зпросов).
  4. Программа не оптимизированна под другой набор фильтров архива, иной стартовый url и обработку исключений (try, except).
  5. Программа оптимизированна под любое количество выводимых на одной странице html статей (10, 20, 30 и т.д.) P.s. отлаживалась под 10; под любое получившееся значение "пагинации".
